{"name": "tool_registration_execution", "description": "Register tools in registry and execute them with parameters", "given": ["A Registry instance", "One or more Tool implementations"], "when": ["Tools are registered via registry.register()", "Tool is retrieved via registry.get()", "Tool is executed with JSON parameters"], "then": ["Tools appear in registry.list()", "Tool executes and returns ToolResult", "Error cases return ToolResult with is_error=true"], "validates": ["Tool trait implementation", "Registry registration", "Tool execution lifecycle"]}
{"name": "agentic_loop_anthropic", "description": "Full agentic loop with tool calls using Anthropic Claude", "given": ["AnthropicClient with valid API key", "Registry with registered tools", "User message requiring tool use"], "when": ["Request sent with tools", "Response contains tool_use blocks", "Tools executed and results returned", "Follow-up request with tool results"], "then": ["Claude calls appropriate tool", "Tool results are incorporated", "Final response contains correct answer"], "validates": ["Anthropic API integration", "Tool calling protocol", "Conversation history management"]}
{"name": "mcp_server_connection", "description": "Connect to MCP server, initialize, list tools, call tools", "given": ["MCP server available (e.g., filesystem)", "McpServerConfig with stdio transport"], "when": ["McpClient::connect() called", "client.initialize() called", "client.list_tools() called", "client.call_tool() called"], "then": ["Connection established", "Tools listed with schemas", "Tool calls return McpToolResult", "Registry integration via merge_mcp works"], "validates": ["MCP protocol implementation", "JSON-RPC 2.0 communication", "McpProxyTool integration"]}
{"name": "streaming_responses", "description": "Stream responses token-by-token from LLM", "given": ["LlmClient implementation", "Request for text generation"], "when": ["create_message_stream() called", "Stream events consumed"], "then": ["MessageStart event received", "ContentBlockDelta events stream text", "MessageStop event signals completion"], "validates": ["SSE parsing", "Stream event types", "Async stream implementation"]}
{"name": "multi_provider", "description": "Same tool works with multiple LLM providers", "given": ["AnthropicClient and OpenAIClient", "Same Registry with tools", "Identical prompts"], "when": ["Request sent to each provider", "Agentic loop executed for each"], "then": ["Both providers call tools correctly", "Both arrive at correct answer", "Tool result format works for both"], "validates": ["LlmClient trait abstraction", "Provider-agnostic tool definitions", "OpenAI function calling compatibility"]}
{"name": "streaming_with_tools", "description": "Stream responses that include tool calls", "given": ["LlmClient with streaming", "Request with tools enabled"], "when": ["create_message_stream() called", "Tool call appears in stream"], "then": ["ContentBlockStart with ToolUse received", "Tool input accumulated from deltas", "Complete tool call reconstructable"], "validates": ["Streaming tool calls", "StreamAccumulator pattern", "Partial JSON assembly"]}
